{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5s843OCCmnv"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AL4a1qfzCopu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2 as cv\n",
        "import glob\n",
        "from pathlib import Path\n",
        "import json\n",
        "import gradio as gr\n",
        "import os\n",
        "from PIL import Image, ImageDraw\n",
        "import threading\n",
        "\n",
        "\n",
        "# Download the images\n",
        "def in_colab() -> bool:\n",
        "    try:\n",
        "        import google.colab\n",
        "        return True\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "REPO_URL = \"https://github.com/Tiromachelan/camera-pose-estimator\"\n",
        "\n",
        "if in_colab():\n",
        "  if not Path(\"camera-pose-estimator/images\").exists():\n",
        "    !git clone {REPO_URL}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoTpoxngChX0"
      },
      "source": [
        "## Calibration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7KtYIwDBXfQ",
        "outputId": "b6418ace-0217-4e2d-b82e-4fda0a2f69f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calibrating data in folder images\n",
            "Processed images/DSCN0504.jpeg\n",
            "Processed images/DSCN0494.jpeg\n",
            "Processed images/DSCN0498.jpeg\n",
            "Processed images/DSCN0499.jpeg\n",
            "Processed images/DSCN0495.jpeg\n",
            "Processed images/DSCN0498.jpeg\n",
            "Processed images/DSCN0499.jpeg\n",
            "Processed images/DSCN0495.jpeg\n",
            "Processed images/DSCN0483.jpeg\n",
            "Processed images/DSCN0488.jpeg\n",
            "Processed images/DSCN0502.jpeg\n",
            "Processed images/DSCN0483.jpeg\n",
            "Processed images/DSCN0488.jpeg\n",
            "Processed images/DSCN0502.jpeg\n",
            "Processed images/DSCN0484.jpeg\n",
            "Processed images/DSCN0492.jpeg\n",
            "Processed images/DSCN0484.jpeg\n",
            "Processed images/DSCN0492.jpeg\n",
            "Processed images/DSCN0493.jpeg\n",
            "Processed images/DSCN0485.jpeg\n",
            "Processed images/DSCN0503.jpeg\n",
            "Processed images/DSCN0493.jpeg\n",
            "Processed images/DSCN0485.jpeg\n",
            "Processed images/DSCN0503.jpeg\n",
            "Processed images/DSCN0489.jpeg\n",
            "Processed images/DSCN0489.jpeg\n",
            "Processed images/DSCN0490.jpeg\n",
            "Processed images/DSCN0486.jpeg\n",
            "Processed images/DSCN0490.jpeg\n",
            "Processed images/DSCN0486.jpeg\n",
            "Processed images/DSCN0501.jpeg\n",
            "Processed images/DSCN0487.jpeg\n",
            "Processed images/DSCN0501.jpeg\n",
            "Processed images/DSCN0487.jpeg\n",
            "Processed images/DSCN0496.jpeg\n",
            "Processed images/DSCN0497.jpeg\n",
            "Processed images/DSCN0496.jpeg\n",
            "Processed images/DSCN0497.jpeg\n"
          ]
        }
      ],
      "source": [
        "class Calibration:\n",
        "    @staticmethod\n",
        "    def calibrateCamera(image_files):\n",
        "        print(f\"calibrating data in folder {image_files}\")\n",
        "        # termination criteria\n",
        "        criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
        "\n",
        "        # prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
        "        pattern_size = (9, 6)\n",
        "        objp = np.zeros((pattern_size[0] * pattern_size[1], 3), np.float32)\n",
        "        objp[:, :2] = np.mgrid[0:pattern_size[0], 0:pattern_size[1]].T.reshape(-1, 2)\n",
        "        # Arrays to store object points and image points from all the images.\n",
        "        objpoints = [] # 3d point in real world space\n",
        "        imgpoints = [] # 2d points in image plane.\n",
        "\n",
        "        images = glob.glob(image_files + '/*.jpeg')\n",
        "\n",
        "        gray = None\n",
        "        for fname in images:\n",
        "            img = cv.imread(fname)\n",
        "            gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
        "            #print(f\"{'processing image '}{fname}\")\n",
        "\n",
        "            # Find the chess board corners\n",
        "            ret, corners = cv.findChessboardCorners(gray, pattern_size, None)\n",
        "\n",
        "            # If found, add object points, image points (after refining them)\n",
        "            if ret == True:\n",
        "                print(f\"{\"Processed \"}{fname}\")\n",
        "                objpoints.append(objp)\n",
        "\n",
        "                corners2 = cv.cornerSubPix(gray,corners, (11,11), (-1,-1), criteria)\n",
        "                imgpoints.append(corners2)\n",
        "        return(cv.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None))\n",
        "\n",
        "class NumpyEncoder(json.JSONEncoder):\n",
        "    def default(self, obj):\n",
        "        if isinstance(obj, np.ndarray):\n",
        "            return obj.tolist()\n",
        "        return json.JSONEncoder.default(self, obj)\n",
        "\n",
        "def calibrate_and_display(folder_path):\n",
        "    ret, mtx, dist, rvecs, tvecs = Calibration.calibrateCamera(folder_path)\n",
        "\n",
        "    files = glob.glob(os.path.join(folder_path, \"*.jpeg\")) + glob.glob(os.path.join(folder_path, \"*.JPEG\"))\n",
        "\n",
        "    results = {\n",
        "        \"return_value\": ret,\n",
        "        \"camera_matrix\": mtx,\n",
        "        \"distortion_coefficients\": dist,\n",
        "        \"rotation_vectors\": rvecs,\n",
        "        \"translation_vectors\": tvecs,\n",
        "        \"image_paths\": files\n",
        "    }\n",
        "    json_output = json.dumps(results, cls=NumpyEncoder, indent=4)\n",
        "\n",
        "    with open(\"calibration.json\", \"w\") as f:\n",
        "        f.write(json_output)\n",
        "\n",
        "    return json_output\n",
        "\n",
        "if in_colab():\n",
        "    calibrate_and_display(\"camera-pose-estimator/images\")\n",
        "else:\n",
        "    calibrate_and_display(\"images\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "TcNTc1ggqBip"
      },
      "outputs": [],
      "source": [
        "class calib:\n",
        "  @staticmethod\n",
        "  def load_calibration(jsonPath:str='calibration.json'):\n",
        "    with open(jsonPath, 'r') as file:\n",
        "            calibrationDict = json.load(file)\n",
        "    #extracting k and distance coefficientse\n",
        "    k = calibrationDict['camera_matrix']\n",
        "    distanceCoeff = calibrationDict['distortion_coefficients']\n",
        "    return k, distanceCoeff\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "h5Ox-iFMqIOd"
      },
      "outputs": [],
      "source": [
        "class Model:\n",
        "  @staticmethod\n",
        "  def load_points(csv_path:str):\n",
        "    points = np.loadtxt(csv_path)\n",
        "    return points"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Gradio Picker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "eXeDhLacqJ85"
      },
      "outputs": [],
      "source": [
        "\n",
        "def launch_point_picker(my_image):\n",
        "    points_store = []\n",
        "    app = None\n",
        "    SELECTED_POINTS = None\n",
        "\n",
        "    def _to_pil_from_numpy(arr: np.ndarray) -> Image.Image:\n",
        "        arr = np.asarray(arr)\n",
        "        # channel-first -> channel-last\n",
        "        if arr.ndim == 3 and arr.shape[0] in (1,3,4) and arr.shape[-1] not in (1,3,4):\n",
        "            arr = np.transpose(arr, (1,2,0))\n",
        "        if np.issubdtype(arr.dtype, np.floating):\n",
        "            # scale floats in [0,1] to [0,255]\n",
        "            arr = (np.clip(arr, 0.0, 1.0) * 255.0).round().astype(np.uint8)\n",
        "        elif arr.dtype != np.uint8:\n",
        "            arr = np.clip(arr, 0, 255).astype(np.uint8)\n",
        "        # Choose mode\n",
        "        if arr.ndim == 2:\n",
        "            return Image.fromarray(arr, mode=\"L\")\n",
        "        if arr.ndim == 3 and arr.shape[2] == 3:\n",
        "            return Image.fromarray(arr, mode=\"RGB\")\n",
        "        if arr.ndim == 3 and arr.shape[2] == 4:\n",
        "            return Image.fromarray(arr, mode=\"RGBA\")\n",
        "        if arr.ndim == 3 and arr.shape[2] == 1:\n",
        "            return Image.fromarray(arr[:,:,0], mode=\"L\")\n",
        "        raise ValueError(f\"Unsupported array shape: {arr.shape}\")\n",
        "\n",
        "    def _to_pil(img):\n",
        "        if isinstance(img, Image.Image):\n",
        "            return img\n",
        "        if isinstance(img, np.ndarray):\n",
        "            return _to_pil_from_numpy(img)\n",
        "        raise gr.Error(\"Set `my_image` to a PIL image or NumPy array before launching.\")\n",
        "\n",
        "    def _draw_points(base_img: Image.Image, pts, radius=5):\n",
        "        img = base_img.copy().convert(\"RGB\")\n",
        "        d = ImageDraw.Draw(img)\n",
        "        for (x, y) in pts:\n",
        "            d.ellipse([x-radius, y-radius, x+radius, y+radius], outline=(255,0,0), width=2)\n",
        "        return img\n",
        "\n",
        "    # Prepare base image from notebook variable\n",
        "    # if 'my_image' not in globals():\n",
        "        # raise RuntimeError(\"Please define `my_image` (PIL image or NumPy array) before running this cell.\")\n",
        "    # base_pil = _to_pil(globals()['my_image'])\n",
        "    base_pil = _to_pil(my_image)\n",
        "\n",
        "    def _refresh_numpy():\n",
        "        \"\"\"Return current preview (base + points) as numpy for Gradio.\"\"\"\n",
        "        return np.array(_draw_points(base_pil, points_store))\n",
        "\n",
        "    def on_click(evt: gr.SelectData):\n",
        "        # Get coordinates robustly\n",
        "        x = y = None\n",
        "        if hasattr(evt, \"index\") and evt.index is not None:\n",
        "            try: x, y = evt.index\n",
        "            except: pass\n",
        "        if (x is None or y is None) and hasattr(evt, \"x\") and hasattr(evt, \"y\"):\n",
        "            x, y = evt.x, evt.y\n",
        "        if x is None or y is None:\n",
        "            return gr.update(), json.dumps(points_store)\n",
        "\n",
        "        # Clamp to image bounds\n",
        "        w, h = base_pil.size\n",
        "        x = int(max(0, min(w-1, x)))\n",
        "        y = int(max(0, min(h-1, y)))\n",
        "\n",
        "        points_store.append([x, y])\n",
        "        return _refresh_numpy(), json.dumps(points_store)\n",
        "\n",
        "    def undo_last():\n",
        "        if points_store:\n",
        "            points_store.pop()\n",
        "        return _refresh_numpy(), json.dumps(points_store)\n",
        "\n",
        "    def clear_points():\n",
        "        points_store.clear()\n",
        "        return np.array(base_pil), \"[]\"\n",
        "\n",
        "    def done_btn_click():\n",
        "        \"\"\"Save to notebook var `selected_points` and close the app.\"\"\"\n",
        "        global SELECTED_POINTS\n",
        "        SELECTED_POINTS = [list(p) for p in points_store]\n",
        "        try:\n",
        "            ip = get_ipython()\n",
        "            if ip is not None:\n",
        "                ip.user_ns['selected_points'] = SELECTED_POINTS\n",
        "        except Exception:\n",
        "            pass\n",
        "        # threading.Thread(target=lambda: app.close(), daemon=True).start()\n",
        "        with open('selected_points.json', 'w') as f:\n",
        "            json.dump(SELECTED_POINTS, f)\n",
        "        return f\"✅ Saved {len(SELECTED_POINTS)} points to `selected_points`. Closing…\"\n",
        "    \n",
        "\n",
        "    with gr.Blocks(title=\"Point Picker (single image)\") as demo:\n",
        "        gr.Markdown(\"**Click on the image to add points.** Use Undo / Clear as needed, then press **Done**.\")\n",
        "        img = gr.Image(\n",
        "            value=np.array(base_pil), label=\"Image (click to add points)\",\n",
        "            type=\"numpy\", interactive=True, sources=[]  # sources=[] disables uploads\n",
        "        )\n",
        "        with gr.Row():\n",
        "            undo_btn = gr.Button(\"↩️ Undo\")\n",
        "            clear_btn = gr.Button(\"🧹 Clear\")\n",
        "            done_btn = gr.Button(\"✅ Done\", variant=\"primary\")\n",
        "        pts_text = gr.Textbox(label=\"Points (JSON)\", value=\"[]\", interactive=False)\n",
        "        status = gr.Markdown(\"\")\n",
        "\n",
        "        # One image used for both input and output\n",
        "        img.select(on_click, inputs=None, outputs=[img, pts_text])\n",
        "        undo_btn.click(lambda: undo_last(), outputs=[img, pts_text])\n",
        "        clear_btn.click(lambda: clear_points(), outputs=[img, pts_text])\n",
        "        done_btn.click(done_btn_click, outputs=[status])\n",
        "\n",
        "\n",
        "        app = demo.launch(inline=True, prevent_thread_lock=True)\n",
        "        return app"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Homography --> Pose (Explicit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# OpenCV Solution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        },
        "id": "u6O4WBM7qlU2",
        "outputId": "5e532181-6628-4128-9834-0aa0aa4dd9b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* Running on local URL:  http://127.0.0.1:7861\n",
            "* To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[]\n"
          ]
        }
      ],
      "source": [
        "# my_image can be a PIL.Image or a NumPy array (H,W[,C])\n",
        "from PIL import Image\n",
        "if in_colab():\n",
        "    my_image = Image.open(\"camera-pose-estimator\" + \"/\" + \"DSCN0851.JPG\")\n",
        "else:\n",
        "    my_image = Image.open(\"DSCN0851.JPG\")\n",
        "\n",
        "selected_points = []\n",
        "\n",
        "app = launch_point_picker(my_image)   # launches inline, non-blocking\n",
        "\n",
        "# ... later, after clicking points and pressing \"Done\":\n",
        "print(selected_points)  # list of [x, y] pixel coordinates\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "cv-env-pip",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
